import copy
import uuid
from typing import Callable, Dict, List, Optional, Tuple

from langchain_core.messages import (
    AIMessage,
    BaseMessage,
    HumanMessage,
    ToolCall,
    ToolMessage,
    RemoveMessage,
)
from langchain_core.tools import BaseTool, tool
from langchain_core.tools.base import InjectedToolCallId
from langgraph.graph.state import CompiledStateGraph
from langgraph.types import Command
from langgraph.utils.runnable import RunnableCallable
from pydantic import BaseModel
from typing_extensions import Annotated

from tw_ai_agents.agents.message_types.base_message_type import (
    ToolMessageInfo,
    State,
)
from tw_ai_agents.config_handler.constants import (
    WHITESPACE_RE,
    SUBAGENT_TOOL_NAME_PREFIX,
    SUBAGENT_TOOL_NAME_SUFFIX,
)


def _normalize_agent_name(agent_name: str) -> str:
    """Normalize an agent name to be used inside the tool name.

    Args:
        agent_name: The name of the agent to normalize.

    Returns:
        A normalized version of the agent name.
    """
    return WHITESPACE_RE.sub("_", agent_name.strip()).lower()


def create_handoff_tool(
    *, agent_name: str, agent_description: str = ""
) -> BaseTool:
    """Create a tool that can handoff control to the requested agent.

    Args:
        agent_name: The name of the agent to handoff control to, i.e.
            the name of the agent node in the multi-agent graph.
            Agent names should be simple, clear and unique, preferably in snake_case,
            although you are only limited to the names accepted by LangGraph
            nodes as well as the tool names accepted by LLM providers
            (the tool name will look like this: `transfer_to_<agent_name>`).

    Returns:
        A tool that can be used to transfer control to another agent.
    """
    tool_name = (
        SUBAGENT_TOOL_NAME_PREFIX
        + f"{_normalize_agent_name(agent_name)}"
        + SUBAGENT_TOOL_NAME_SUFFIX
    )

    class BaseArgsSchema(BaseModel):
        tool_call_id: Annotated[str, InjectedToolCallId]
        message_for_subagent: str

    @tool(tool_name, description=agent_description, args_schema=BaseArgsSchema)
    def handoff_to_agent(
        tool_call_id: Annotated[str, InjectedToolCallId],
        message_for_subagent: str,
    ) -> Command:
        """Ask another agent for help."""
        tool_message = ToolMessage(
            content=f"Successfully transferred to {agent_name}\n\n"
            f"## Message from the supervisor\n"
            f"{message_for_subagent}",
            name=tool_name,
            tool_call_id=tool_call_id,
        )
        return Command(
            goto=agent_name,
            graph=Command.PARENT,
            update={
                "messages": [tool_message],
                "message_from_supervisor": [message_for_subagent],
            },
        )

    return handoff_to_agent


def create_handoff_back_messages(
    agent_name: str, supervisor_name: str
) -> tuple[AIMessage, ToolMessage]:
    """Create a pair of (AIMessage, ToolMessage) to add to the message history when returning control to the supervisor."""
    tool_call_id = str(uuid.uuid4())
    tool_name = f"transfer_back_to_{_normalize_agent_name(supervisor_name)}"
    tool_calls = [ToolCall(name=tool_name, args={}, id=tool_call_id)]
    return (
        AIMessage(
            content=f"Transferring back to {supervisor_name}",
            tool_calls=tool_calls,
            name=agent_name,
        ),
        ToolMessage(
            content=f"Successfully transferred back to {supervisor_name}",
            name=tool_name,
            tool_call_id=tool_call_id,
        ),
    )


def _make_call_agent(
    agent: CompiledStateGraph,
    add_handoff_back_messages: bool,
    supervisor_name: str,
) -> Callable[[Dict], Dict]:
    """
    Create a function that calls an agent and processes its output.
    This function is what is actually executed when the handoff to a sub-agent happens.
    Here is were we process messages going to and coming from sub-agents.

    Args:
        agent: The agent to call.
        add_handoff_back_messages: Whether to add handoff back messages.
        supervisor_name: The name of the supervisor agent.

    Returns:
        A callable that invokes the agent and processes its output.
    """

    def _process_output(
        output: Dict, old_messages: Optional[Dict] = None
    ) -> agent.output_schema:
        output = output.copy()
        old_messages = old_messages or {}
        old_messages = old_messages.copy()
        all_messages = old_messages + output["messages"]

        if add_handoff_back_messages:
            # Add handoff back messages using AIMessage and HumanMessage
            all_messages.extend(
                create_handoff_back_messages(agent.name, supervisor_name)
            )

        # Remove last three messages, which are
        # 1. the Tool message generated by the handoff function
        # 2. the HumanMessage we generate in process_input
        # 3. the AI Message generated as response from the Tool/Sub-agent
        # Replace the content of the tool message with the reply from the subagent

        # Find the last ToolMessage that comes before the last HumanMessage
        last_tool_idx = None

        # Iterate in reverse to find the first HumanMessage and check if the previous one is a ToolMessage
        for i in range(len(all_messages) - 1, 0, -1):
            if (
                isinstance(all_messages[i], HumanMessage)
                and getattr(all_messages[i], "from_user", True) == False
            ):
                if isinstance(all_messages[i - 1], ToolMessage):
                    last_tool_idx = i - 1
                break

        if last_tool_idx is None:
            raise ValueError("Could not find appropriate ToolMessage to update")

        # Update the content of that ToolMessage with the final AI response, to give them back to UI
        new_tools_called = []
        potential_user_messages = []
        for idx in range(last_tool_idx, len(all_messages)):
            message = all_messages[idx]
            if isinstance(message, ToolMessage):
                # get the previous ai message, if available. It contains the params of the tool call
                previous_ai_message = all_messages[idx - 1] if idx > 0 else None
                parameters = (
                    previous_ai_message.tool_calls[0].get("args", {})
                    if previous_ai_message
                    else {}
                )

                new_tools_called.append(
                    ToolMessageInfo(
                        content=message.content,
                        name=message.name,
                        tool_call_id=message.tool_call_id,
                        id=message.id,
                        parameters=parameters,
                    )
                )

            if (
                isinstance(message, AIMessage)
                and i + 1 < len(all_messages)
                and isinstance(all_messages[i + 1], HumanMessage)
                and getattr(all_messages[i + 1], "from_user", True) == True
            ):
                # We found a User Conversation done inside this sub-agent
                potential_user_messages.append(message)
                potential_user_messages.append(all_messages[i + 1])
        a = 1
        old_messages_to_remove = all_messages[
            last_tool_idx - 1 : last_tool_idx + 1
        ]
        to_remove_messages = [
            RemoveMessage(id=m.id) for m in old_messages_to_remove
        ]
        to_append_messages = copy.deepcopy(old_messages_to_remove)
        for to_append_message in to_append_messages:
            to_append_message.id = None
        # here we keep the same ID so that the ToolMessage inside messages is updated.
        # We are not adding a new message, just update the ToolMessage that is there and was created by create_handoff_tool
        to_append_messages[-1].content = f"{all_messages[-1].content}"

        return {
            **output,
            "messages": to_remove_messages
            + potential_user_messages
            + to_append_messages,
            # we add new tools before because this code is called when going back up on the graph.
            "tools_called": new_tools_called + output["tools_called"],
            # Remove last message from supervisor, as it was used in the supervisor processing
            "message_from_supervisor": [None],
        }

    def _process_input(
        input: State,
    ) -> Tuple[agent.input_schema, Optional[List[BaseMessage]]]:
        # add messages_to_from_user to the correct_input
        messages_from_to_user = []
        for message in input["messages"]:
            if isinstance(message, HumanMessage) and getattr(
                message, "from_user", True
            ):
                messages_from_to_user.append(message)
        input.add_messages_to_from_user(messages_from_to_user)

        # return on the last ToolMessage, convert it to a HumanMessage
        last_message = input["messages"][-1]
        other_messages = input["messages"]
        # qua come content devo prendere il message from subagent
        if isinstance(last_message, ToolMessage):
            last_message = HumanMessage(last_message.content, from_user=False)
        else:
            raise ValueError(
                f"Expected last message to be a ToolMessage, got {type(last_message)}"
            )
        input["messages"] = [last_message]
        return input, other_messages

    def call_agent(input_state: Dict) -> Dict:
        is_copy = copy.deepcopy(input_state)
        state, old_messages = _process_input(input_state)
        output = agent.invoke(state)
        output_dict = _process_output(output, old_messages)
        return output_dict

    async def acall_agent(state: Dict) -> Dict:
        state, old_messages = _process_input(state)
        output = await agent.ainvoke(state)
        return _process_output(output, old_messages)

    return RunnableCallable(call_agent, acall_agent)
